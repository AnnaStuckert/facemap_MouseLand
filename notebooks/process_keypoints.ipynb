{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorials shows how to process keypoints using Facemap. \n",
    "The pose model can be initialized with the following parameters:\n",
    "\n",
    "**filenames**: (2D-list)\n",
    "    List of filenames to be processed.\n",
    "\n",
    "**bbox**: (list)\n",
    "    Bounding box for cropping the video [x1, x2, y1, y2]. If not set, the entire frame is used.\n",
    "\n",
    "**bbox_set**: (bool)\n",
    "    Flag to indicate whether the bounding box has been set. Default is False.\n",
    "\n",
    "**resize**: (bool)\n",
    "    Flag to indicate whether the video needs to be resized.\n",
    "\n",
    "**add_padding**: (bool)\n",
    "    Flag to indicate whether the video needs to be padded. Default is False.\n",
    "\n",
    "**gui**: (object)\n",
    "    GUI object.\n",
    "\n",
    "**GUIobject**: (object)\n",
    "    GUI mainwindow object.\n",
    "\n",
    "**net**: (object)\n",
    "    PyTorch model object.\n",
    "\n",
    "**model_name**: (str)\n",
    "    Name of the model to be used for pose estimation. Default is None which uses the pre-trained model.\n",
    "\n",
    " For more information on the Pose class see [here](https://github.com/MouseLand/facemap/blob/main/facemap/pose/pose.py)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.24.3\n",
      "python version: 3.9.7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0,  '/home/stringlab/Facemap/facemap')\n",
    "from facemap.pose import pose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process single video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/stringlab/Desktop/cam1_test.avi' # Set your video path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pose model. \n",
    "model = pose.Pose(filenames=[[filepath]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda set as device\n",
      "Loading model parameters from: /home/stringlab/.facemap/models/facemap_model_params.pth\n",
      "Setting model name to: facemap_model_state\n",
      "Loading model state from: /home/stringlab/.facemap/models/facemap_model_state.pt\n",
      "\n",
      "Processing video: /home/stringlab/Desktop/cam1_test.avi\n",
      "Using params:\n",
      "\tbbox: [0, 646, 0, 864]\n",
      "\tbatch size: 1\n",
      "\tresize: True\n",
      "\tpadding: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stringlab/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference speed: 221.27652211016874 fps\n",
      "Saved keypoints: /home/stringlab/Desktop/cam1_test_FacemapPose.h5\n",
      "Saved metadata: /home/stringlab/Desktop/cam1_test_FacemapPose_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "# process video and save results\n",
    "model.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process batch of videos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process a batch of videos using the same model and parameter settings, set `filenames` to a list of video files and run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileslist = [filepath, filepath] # Set your list of video paths here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pose model\n",
    "model = pose.Pose(filenames=[fileslist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda set as device\n",
      "Loading model parameters from: /home/stringlab/.facemap/models/facemap_model_params.pth\n",
      "Setting model name to: facemap_model_state\n",
      "Loading model state from: /home/stringlab/.facemap/models/facemap_model_state.pt\n",
      "\n",
      "Processing video: /home/stringlab/Desktop/cam1_test.avi\n",
      "Using params:\n",
      "\tbbox: [0, 646, 0, 864]\n",
      "\tbatch size: 1\n",
      "\tresize: True\n",
      "\tpadding: True\n",
      "Inference speed: 280.087415130115 fps\n",
      "Saved keypoints: /home/stringlab/Desktop/cam1_test_FacemapPose.h5\n",
      "Saved metadata: /home/stringlab/Desktop/cam1_test_FacemapPose_metadata.pkl\n",
      "\n",
      "Processing video: /home/stringlab/Desktop/cam1_test.avi\n",
      "Using params:\n",
      "\tbbox: [0, 646, 0, 864]\n",
      "\tbatch size: 1\n",
      "\tresize: True\n",
      "\tpadding: True\n",
      "Inference speed: 233.99128057928337 fps\n",
      "Saved keypoints: /home/stringlab/Desktop/cam1_test_FacemapPose.h5\n",
      "Saved metadata: /home/stringlab/Desktop/cam1_test_FacemapPose_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "model.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `load_visualize_keypoints.ipynb` for how to load and visualize the saved output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
